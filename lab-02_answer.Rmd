---
title: "Sara's answers lab 02 smwa"
author: "Sara Manders"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

## Motivation

Linear regression is a workhorse model of a Marketing Analyst's toolkit.
This is because it gives them the ability to describe data patterns, predict the value of marketing metrics in data and potentially make causal claims about the relationships between multiple variables. 

In this tutorial you will apply linear regression to get first hand experience with these tools.
We will focus both on how to linear regression in `R` and how to correctly interpret the results.
You will use linear regression to evaluate the association between product characteristics and product price in an internet mediated market.

## Learning Goals

By the end of this tutorial you will be able to:

1. Estimate Single and Multiple Regression models with R.
2. Interpret regression coefficients.
3. Discuss likely biases in regression coefficients due to omitted variable bias.
4. Discuss why regression standard errors may need to be adjusted for heteroskedasticity or clustering.
5. Estimate Fixed Effect regressions with and without clustered standard errors.
6. Present regression coefficients in a table and in a plot.

## Instructions to Students

These tutorials are **not graded**, but we encourage you to invest time and effort into working through them from start to finish.
Add your solutions to the `lab-02_answer.Rmd` file as you work through the exercises so that you have a record of the work you have done.

Obtain a copy of both the question and answer files using Git.
To clone a copy of this repository to your own PC, use the following command:

```{bash, eval = FALSE}
git clone https://github.com/tisem-digital-marketing/smwa-lab-02.git
```

Once you have your copy, open the answer document in RStudio as an RStudio project and work through the questions.

The goal of the tutorials is to explore how to "do" the technical side of social media analytics.
Use this as an opportunity to push your limits and develop new skills.
When you are uncertain or do not know what to do next - ask questions of your peers and the instructors on the class Slack channel `#lab02-discussion`.

\newpage

## Multiple Regression Analysis

The advent of the internet, and the rise in user generated content has had a large effect on sex markets.
In 2008 and 2009, [Scott Cunningham](https://www.scunning.com/) and [Todd Kendall](https://www.compasslexecon.com/professionals/todd-d-kendall/) surveyed approximately 700 US internet mediated sex workers.
The questions they asked included information about their illicit and legal labor market experiences and their demographics.
Part of the survey asked respondents to share information about each of the previous four sessions with clients.

To gain access to the data, run the following code to download it and save it in the file `data/sasp_panel.dta`:

```{r, cache= TRUE}
url <- "https://github.com/scunning1975/mixtape/raw/master/sasp_panel.dta"
# where to save data
out_file <- "data/sasp_panel.dta"
# download it!
download.file(url, 
              destfile = out_file, 
              mode = "wb"
              )
```

The data include the log hourly price, the log of the session length (in hours), characteristics of the client (such as whether he was a regular), whether a condom was used, and some characteristics of the provider (such as their race, marital status and education level).
The goal of this exercise is to estimate the price premium of unsafe sex and think through any bias in the coefficients within the regression models we estimate.

You might need to use the following `R` libraries throughout this exercise:^[
  If you haven't installed one or more of these packages, do so by entering `install.packages("PKG_NAME")` into the R console and pressing ENTER.
]

```{r, eval = TRUE, message=FALSE, warning=FALSE}
library(haven) # to read stata datasets
library(dplyr)
library(tidyr)
library(fixest)
library(broom)
library(ggplot2)
library(modelsummary)
```

1. Load the data. The data is stored as a Stata dataset, so it can be loaded with the `read_dta()` function from `haven`.

```{r}
sex_data <- read_dta("data/sasp_panel.dta")

#proposed solution
sasp <- read_dta("data/sasp_panel.dta")
```


2. Some rows of the data have missing values. Let's drop these.^[
  Generally, we need to be quite careful when we make decisions about dropping rows of data, and think through what the consequences of it might be.
  We've not done this here because our goal was to illustrate how to estimate and interpret regression estimates, but we would encourage you to be careful when you do this in your own work.
  At a minimum, you should mention why you've dropped rows, and whether there is likely to be selection bias in your subsequent results.
]
Write a short command to drop any rows which have missing values from the data.

```{r}
sex_data <- sex_data %>% na.omit()

#proposed solution
sasp <- sasp %>%
    drop_na()
```


As mentioned above, the focus for the rest of this exercise is the price premium for unprotected sex. 
In the `sasp` data, there is a variable `lnw` which is the log of the hourly wage and a variable `unsafe` which takes the value 1 if there was unsafe sex during the client's appointment and 0 otherwise.

3. Produce a diagram that plots a histogram of log hourly wage, `lnw`, for sessions featuring either unsafe and safe sex. 
Your plot should therefore have two histograms, potentially overlaying each other.
Does there appear to be a difference in price between safe and unsafe sex?

```{r}

ggplot(sex_data, aes(x=lnw, fill=unsafe, color=unsafe)) +
    geom_histogram(position = "identity") +
    xlab("Log Hourly Wage Sex Workers") +
    ylab("Count") +
    ggtitle("Histogram of log hourly wage for safe vs. unsafe sex",
            subtitle = "Hourly wage of online sex workers - 1 = unsafe (no condom). 0 = safe (condom)")+
    facet_wrap(~ unsafe)

ggplot(sex_data, aes(x=lnw, fill=unsafe, color=unsafe)) +
    geom_histogram(position = "identity", alpha = 0.5) +
    xlab("Log Hourly Wage Sex Workers") +
    ylab("Count") +
    ggtitle("Histogram of log hourly wage for safe vs. unsafe sex",
            subtitle = "Hourly wage of online sex workers - 1 = unsafe (no condom). 0 = safe (condom)")+
    scale_color_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2")


#proposed solution
sasp %>%
    ggplot(aes(x= lnw, fill = factor(unsafe))) +
    geom_histogram(aes(y=stat(count/sum(count))), alpha = 0.6) +
    scale_fill_manual(values=c("#69b3a2", "#404080")) +
    ylab("Fraction of Bookings") +
    xlab("Log Hourly Wage") +
    theme_bw()
```

4. Let's formalize this idea with a regression.
Run a single variable regression of log hourly wage, `lnw` on the variable `unsafe`.
Report the results.

```{r}

reg1 <- lm(unsafe ~ lnw, data = sex_data)
reg1

# Coefficients
#  Intercept = 0.71145
#  lnw = -0.03154

summary(reg1)
# p-value = .1978 > .05 --> can't reject H0
# regr. estimate = .71145*** (p <.001)


#proposed solution
simple_reg <- lm(lnw ~ unsafe, data = sasp)

tidy(simple_reg, conf.int = TRUE)

```


5. Interpret the coefficient on `unsafe`.
Is it statistically significant?

The coefficient is negative, but not statistically significant. Therefore, whether the sex was (un)safe is not expected to significantly effect the hourly wage.

#proposed solution
(1) On average, unsafe sex decreases the log hourly wage by 0.035
(2) On average, unsafe sex decreases the hourly wage by ± 3.5%

Interpretation 2 utilizes the log-level interpretation of the regression. Technically, the size of the effect is (exp B1 - 1) * 100%, for small values of B1, exp B1-1 = ± B

Statistical significance: the p-value = .198 > .05, so the effect is not statistically significant at the 5% level of significance.


6. A single variable regression most likely suffers from omitted variable bias. 
Explain what omitted variable bias is, and why it might impact your regression estimates.

The omitted variable bias is the bias in the OLS estimator that arises when the regressor, X, is correlated with an omitted variable (non-included variables in the model which are determinants of the dependent variable). For omitted variable bias to occur, two conditions must be fulfilled:
1. X is correlated with the omitted variable
2. The omitted variable is a determinant of the dependent variable Y.
Together, these result in a violation of the first OLS assumption E(u(i) | X(i)) = 0.

This might imparct our regression estimates, because the dependent variable has not been optimally explained and not including these omitted variables might return either false positives in findings or non-statistical findings because not all determinants have been included in the analysis.

#proposed solution

Omitted Variable Bias = the effect of leaving out one or more relevant variables on the regression coefficients in the "misspecified" regression.

For omitted variable bias to occur we need:
1. The included X variable(s) to be correlated with the omitted variable
2. The omtitted variable to be a relevant determinant of y

(1) and (2) leave to a violation of the exogeneity assumption E(u(i)|x(i)) = 0. When we don't have exogeneity,

E (B) = beta + bias

which means that our estimated coefficient cannot accurately estimate the true population parameter, and thus can't be interpreted causally.

7. Add the log of the length of the session, `llength`, as a second variable to your regression.
Report the results.
Did the coefficient on `unsafe` change?

```{r}

reg2 <- lm(unsafe ~ lnw + llength, sex_data)
summary(reg2)

# The p-value of the overall test = <.001 which implies statistical significance
# However, neither the intercept nor the coefficient of lnw are statistically significant.
# Only the llength has a (small positive; 6,5%) statistical signficant effect on unsafe, which means that a longer length of the session increases the likelihood for a session to have included unsafe sex.

#Regr estimate = 0.241956 (p >.05)

#proposed solution

twovar_reg <- lm(lnw ~ unsafe + llength, data = sasp)

tidy(twovar_reg, conf.int = TRUE)

```


8. Explain why ignoring `llength` in your regression led to the coefficient on `unsafe` to be different in sign in the single variable regression than in the two variable regression.

#proposed solution

The formula for Omitted Variable Bias (assuming omitted variable, x(2) has coefficient Beta(2))

E(B(1) = Beta(1) + Beta(2) * ((Cov(x1, x2)/ std dev(x2))))

One  would reason that:
* Beta(2) < 0 ... longer sessions lead to quantity discounts
* Cov (x1, x2) > 0 ... longer sessions more likely to feature unsafe sex

--> Bias is negative, so that:
E (B(1)) = Beta (1) + something negative
< Beta(1)

Dus de estimate van variable x1 is kleiner dan de werkelijke waarde van x1 (unsafe sex)

9.  Add a third variable to the regression, whether the client is a regular or not (`reg` in the data).
Report your results and comment on any change in the regression estimate of `unsafe`.

```{r}
reg3 <- lm(unsafe ~ lnw + llength + reg, sex_data)
summary(reg3)

# Regr. estimate of unsafe = 0228257 (p>.05) --> not statistically significant

#proposed solution

threevar_reg <- lm(lnw ~ unsafe + llength + reg, data =sasp)

tidy(threevar_reg, conf.int = TRUE)

```


10. When discussing your interim results with a friend who is a bit of a statistical whiz they make the following remark: "I think you're not getting the expected results due to unobserved heterogeneity. Try adding fixed effects for each provider."
What is unobserved heterogeneity? Why might it matter?

Unobserved heterogeneity implies there is a group difference within the sample (unobserved), within groups there is homogeneity, but across groups there is heterogeneity. It matters because researchers can be severely misled if not accounting for these group differences.

#proposed solution

Unobserved heterogeneity: unmeasured (typically time invariant) differences between (in this case) providers.

Think as follows: we have not included any variable about the provider so far - and there might be something about them that influences the prices they charge AND their willingness to engage in unsafe sex.

Omitting unobserved heterogeneity - which in what follows is provider fixed effects - leads to omitted variable bias.

UP TO US: THINK THROUGH THE LIKELY DIRECTION OF THAT BIAS

Solving omitted unobserverd heterogeneity, would most likely solve the omitted variable bias.

http://www.eco.uc3m.es/docencia/EconomiaAplicada/materiales/PanelData_2classes.pdf - Fixed Effects model:

Y(it) = β(0) + β(1)X(it) + δ(0)d2(t) + a(i) + u(it)

ai = unobservable, time invariant variation or heterogeneity
u(it) = usual error term (includes unobserved factors affecting Y(it) that change over time)
v(it) = a(i) + u(it) --> composite error: it has a constant component and a component that changes over time

Y(it) = β(0) + β(1)X(it) + δ(0)d2(t) + v(it)

To consistently estimate β(1) using OLS, we need to assume that X(it) is NOT correlated with v(it)

11. The data has a unique identifier for each provider in the `id` column.
Use the `feols()` command from the `fixest` package to re-estimate your regression in (9) adding the provider ID fixed effects.
Report your results with 'normal' standard errors (i.e. no clustering).

```{r}

library(fixest)

ols_fe <- feols(unsafe ~ lnw + llength + reg 
                | #Fixed effects go after the |
                    id,
                data = sex_data)

summary(ols_fe)

# Estimates of all IVs are significant at least at the 10% level

coefs_fe <- tidy(ols_fe, se ="standard", conf.int = TRUE)
coefs_fe

# Non-clustered standard errors --> all IVs statistically significant <.001 


#proposed solution

fixedeff <- feols(lnw ~ unsafe + reg + llength | id, data = sasp)

tidy(fixedeff, se = "standard", conf.int = TRUE)

round(exp(mean(sasp$lnw)))
#275

round(exp(mean(sasp$lnw))) * 1.05
#288.75

Increase <- (round(exp(mean(sasp$lnw)))*.05)
Increase #13.75 p. hour (4.7%)
```


12. Interpret your new results from (11).
Is the coefficient on `unsafe` now statistically significant?
Is the coefficient large from a 'marketing' viewpoint?

Where exactly can I find the coefficient on unsafe????


#proposed solution

On average, unsafe sex increases the log hourly wage by 4.7% (holding other variables constant).

Our effect is statistically significant at the 10% level of significance (p-value <.1) but not at the 5% level (p-value >.05).

Is this big? It's approximately a 5% increase. The mean hourly wage is r round(exp(mean(sasp$lnw))-1,0) so a five percent increase is 'round(0.05*(exp(mean(sasplwn)))-1),0)' per hour. That really isn't that much of a premium.


Your next concern should be the standard errors - and whether we have 'correctly' adjusted for heteroskedasticity and/or clustering.

13. Produce a plot that visualizes the relationship between the predicted values of `lnw` from your regression on the horizontal axis and the residuals from the regression on the vertical axis.^[
The function `predict(MODEL_NAME)` will create a column of predicted values from a regression stored as `MODEL_NAME`.
The function `residuals(MODEL_NAME)` will create a column of residual values from a regression stored as `MODEL_NAME`.
]
Does there appear to be evidence of heteroskedasticity?


```{r}

pred_val <- predict(ols_fe)
pred_val
res_val <- residuals(ols_fe)
res_val

df <- cbind(pred_val, res_val)
df <- data.frame(df)

ggplot(df, aes(x = pred_val, y = res_val)) +
    geom_point()

# Yes, there appears to be evidence of heteroskedasticity

# Or I could do:

sex_data <- sex_data %>%
    mutate(
        residuals = resid(ols_fe),
        fitted_val = predict(ols_fe)
    )

sex_data %>%
    ggplot(aes(x = fitted_val, 
               y = residuals,
               alpha = 0.35)) +
    geom_point() +
    theme_bw() +
    theme(legend.position = "none")



#proposed solution

sasp <- sasp%>%
    mutate(resid = residuals(fixedeff),
           fitted = predict(fixedeff))

sasp %>%
    ggplot(aes(x = fitted, y = resid)) +
    geom_point() +
    geom_smooth() +
    theme_bw() +
    ggtitle("Not much evidence of heteroskedasticity")

```


14. Report regression results that use heteroskedasticity robust standard errors. 
You might be able to do this **without** re-estimating the regression model in (11). 
Does the standard error on `unsafe` change by much?
Is this consistent with what you found graphically above?

```{r}
#install.packages("estimatr")
library(estimatr)
library(broom)

ols1a <- lm_robust(unsafe ~ lnw + llength + reg | id,
                   data = sex_data)

tidy(ols1a, conf.int = TRUE)


#proposed solution

tidy(fixedeff, se ="hetero", conf.int = TRUE)
#Doesn't change much

```


15. Report results that allow the standard errors to be clustered by `id` (i.e. clustered at the provider level).
Again, you might be able to do this **without** re-estimating the regression model in (11). 
Why might you want to cluster the standard errors this way?

```{r}

ols2 <- lm_robust(unsafe ~ lnw + llength + reg | id,
                  clusters = id,
                  data = sex_data)

tidy(ols2, conf.int = TRUE)


#proposed solution

tidy(fixedeff, se = "cluster", conf.int = TRUE)

#You might want to cluster the standard errors by id, because those are the fixed effects. This way, you basically take into account differences between clusters based on time invariant factors between the observations.

```


Marketers are generally interested in whether effects they find are heterogeneous, i.e. whether the reported coefficients vary across different observable characteristics.

16. Estimate a regression model that allows the price effect of unsafe sex to differ for customers who are regulars to those who aren't.
Do this by modifying your regression command from (11).
Report your results and discuss your findings.

```{r}

ols2a <- feols(unsafe ~ lnw + llength + id |
                   reg,
               data = sex_data)

tidy(ols2a, se = "standard", conf.int = TRUE)


#proposed solution

fixedeff_het <- feols(lnw~unsafe:reg + unsafe + reg + llength | id,
                      cluster = ~id,
                      data=sasp)

tidy(fixedeff_het, conf.int = TRUE)

```


17. Interpret the results you found in (16).

???


#proposed solution

Neither unsafe, nor unsafe:reg are statistically significant (p-value > .1), so these findings are not overwhelming evidence for differences.

If we would look at the coefficients, we find that there is evidence of price discrimination. 
Providers charge a higher price for unsafe sex with clients who are regulars than those who aren't.

A potential reason could be that regulars are less likely to switch to a different provider, so they're taken advantage of and charged a higher premium.
I wouldn't want to push this argument too hard.

18. Are the effects you documented *causal*, *descriptive* or *predictive*?  Explain your answer.

Descriptive, because ...


#proposed solution

For the heterogeneity results - descriptive. There is a bunch of "selection on unobservables" issues and potentially omitted variables that would make causal interpretation highly arguable.

For the earlier regressions - the authors of the survey would argue causal interpretation after adding the fixed effects for the provider.
Essentially, they'd argue that the coefficient on unsafe is being estimated by differences in wages between unsafe and safe sex within each provider.

Now that you have run a series of regressions, you want to present the results in a way that you could use in a report or a presentation.

19. Take your regression estimates and produce a regression table to summarize four of them in one place. 
You can choose any of the estimates you like to produce the table, but we encourage you to think about how each column adds something to a story you could tell to explain your findings.
The final result should look similar to a regression table you see in academic publications.

```{r}


#proposed solution

#a simple table - minimum customization

mods <- list(simple_reg,
             threevar_reg,
             fixedeff,
             fixedeff_het)

msummary(mods,
         coef_omit = "Interc",
         gof_omit = "AIC|BIC|Log|Pseudo|F")



```

20. Take your regression estimates and produce a coefficient plot to summarize four of them in one place. 
You can choose any of the estimates you like to produce the plot, but we encourage you to think about the plot you produce can be used as part of a story you could tell to explain your findings.

```{r}


#proposed solution

#heterog is more difficult to plot, so Lachlan ignored it

mods2 <- list(simple_reg,
             threevar_reg,
             fixedeff)

modelplot(mods2,
          coef_omit = "Interc|reg|11") +
    geom_vline(xintercept = 0,
               alpha=.5,
               linetype = "dashed") +
    xlab("Coefficient Estimate + 95% CI") +
    coord_flip() +
    theme_bw()

```

## License

This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).

## Suggested Citation

Deer, Lachlan and de With, Hendrik. 2021. Social Media and Web Analytics: Lab 2 - Multiple Regression in the Wild. Tilburg University. url = "https://github.com/tisem-digital-marketing/smwa-lab-02"
