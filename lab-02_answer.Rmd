---
title: "Sara's answers lab 02 smwa"
author: "Sara Manders"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

## Motivation

Linear regression is a workhorse model of a Marketing Analyst's toolkit.
This is because it gives them the ability to describe data patterns, predict the value of marketing metrics in data and potentially make causal claims about the relationships between multiple variables. 

In this tutorial you will apply linear regression to get first hand experience with these tools.
We will focus both on how to linear regression in `R` and how to correctly interpret the results.
You will use linear regression to evaluate the association between product characteristics and product price in an internet mediated market.

## Learning Goals

By the end of this tutorial you will be able to:

1. Estimate Single and Multiple Regression models with R.
2. Interpret regression coefficients.
3. Discuss likely biases in regression coefficients due to omitted variable bias.
4. Discuss why regression standard errors may need to be adjusted for heteroskedasticity or clustering.
5. Estimate Fixed Effect regressions with and without clustered standard errors.
6. Present regression coefficients in a table and in a plot.

## Instructions to Students

These tutorials are **not graded**, but we encourage you to invest time and effort into working through them from start to finish.
Add your solutions to the `lab-02_answer.Rmd` file as you work through the exercises so that you have a record of the work you have done.

Obtain a copy of both the question and answer files using Git.
To clone a copy of this repository to your own PC, use the following command:

```{bash, eval = FALSE}
git clone https://github.com/tisem-digital-marketing/smwa-lab-02.git
```

Once you have your copy, open the answer document in RStudio as an RStudio project and work through the questions.

The goal of the tutorials is to explore how to "do" the technical side of social media analytics.
Use this as an opportunity to push your limits and develop new skills.
When you are uncertain or do not know what to do next - ask questions of your peers and the instructors on the class Slack channel `#lab02-discussion`.

\newpage

## Multiple Regression Analysis

The advent of the internet, and the rise in user generated content has had a large effect on sex markets.
In 2008 and 2009, [Scott Cunningham](https://www.scunning.com/) and [Todd Kendall](https://www.compasslexecon.com/professionals/todd-d-kendall/) surveyed approximately 700 US internet mediated sex workers.
The questions they asked included information about their illicit and legal labor market experiences and their demographics.
Part of the survey asked respondents to share information about each of the previous four sessions with clients.

To gain access to the data, run the following code to download it and save it in the file `data/sasp_panel.dta`:

```{r, cache= TRUE}
url <- "https://github.com/scunning1975/mixtape/raw/master/sasp_panel.dta"
# where to save data
out_file <- "data/sasp_panel.dta"
# download it!
download.file(url, 
              destfile = out_file, 
              mode = "wb"
              )
```

The data include the log hourly price, the log of the session length (in hours), characteristics of the client (such as whether he was a regular), whether a condom was used, and some characteristics of the provider (such as their race, marital status and education level).
The goal of this exercise is to estimate the price premium of unsafe sex and think through any bias in the coefficients within the regression models we estimate.

You might need to use the following `R` libraries throughout this exercise:^[
  If you haven't installed one or more of these packages, do so by entering `install.packages("PKG_NAME")` into the R console and pressing ENTER.
]

```{r, eval = TRUE, message=FALSE, warning=FALSE}
library(haven) # to read stata datasets
library(dplyr)
library(tidyr)
library(fixest)
library(broom)
library(ggplot2)
library(modelsummary)
```

1. Load the data. The data is stored as a Stata dataset, so it can be loaded with the `read_dta()` function from `haven`.

```{r}
sex_data <- read_dta("data/sasp_panel.dta")

#proposed solution
sasp <- read_dta("data/sasp_panel.dta")
```


2. Some rows of the data have missing values. Let's drop these.^[
  Generally, we need to be quite careful when we make decisions about dropping rows of data, and think through what the consequences of it might be.
  We've not done this here because our goal was to illustrate how to estimate and interpret regression estimates, but we would encourage you to be careful when you do this in your own work.
  At a minimum, you should mention why you've dropped rows, and whether there is likely to be selection bias in your subsequent results.
]
Write a short command to drop any rows which have missing values from the data.

```{r}
sex_data <- sex_data %>% na.omit()

#proposed solution
sasp <- sasp %>%
    drop_na()
```


As mentioned above, the focus for the rest of this exercise is the price premium for unprotected sex. 
In the `sasp` data, there is a variable `lnw` which is the log of the hourly wage and a variable `unsafe` which takes the value 1 if there was unsafe sex during the client's appointment and 0 otherwise.

3. Produce a diagram that plots a histogram of log hourly wage, `lnw`, for sessions featuring either unsafe and safe sex. 
Your plot should therefore have two histograms, potentially overlaying each other.
Does there appear to be a difference in price between safe and unsafe sex?

```{r}

ggplot(sex_data, aes(x=lnw, fill=unsafe, color=unsafe)) +
    geom_histogram(position = "identity") +
    xlab("Log Hourly Wage Sex Workers") +
    ylab("Count") +
    ggtitle("Histogram of log hourly wage for safe vs. unsafe sex",
            subtitle = "Hourly wage of online sex workers - 1 = unsafe (no condom). 0 = safe (condom)")+
    facet_wrap(~ unsafe)

ggplot(sex_data, aes(x=lnw, fill=unsafe, color=unsafe)) +
    geom_histogram(position = "identity", alpha = 0.5) +
    xlab("Log Hourly Wage Sex Workers") +
    ylab("Count") +
    ggtitle("Histogram of log hourly wage for safe vs. unsafe sex",
            subtitle = "Hourly wage of online sex workers - 1 = unsafe (no condom). 0 = safe (condom)")+
    scale_color_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2")


#proposed solution
sasp %>%
    ggplot(aes(x= lnw, fill = factor(unsafe))) +
    geom_histogram(aes(y=stat(count/sum(count))), alpha = 0.6) +
    scale_fill_manual(values=c("#69b3a2", "#404080")) +
    ylab("Fraction of Bookings") +
    xlab("Log Hourly Wage") +
    theme_bw()
```

4. Let's formalize this idea with a regression.
Run a single variable regression of log hourly wage, `lnw` on the variable `unsafe`.
Report the results.

```{r}

reg1 <- lm(unsafe ~ lnw, data = sex_data)
reg1

# Coefficients
#  Intercept = 0.71145
#  lnw = -0.03154

summary(reg1)
# p-value = .1978 > .05 --> can't reject H0
# regr. estimate = .71145*** (p <.001)


#proposed solution
simple_reg <- lm(lnw ~ unsafe, data = sasp)

tidy(simple_reg, conf.int = TRUE)

```


5. Interpret the coefficient on `unsafe`.
Is it statistically significant?

The coefficient is negative, but not statistically significant. Therefore, whether the sex was (un)safe is not expected to significantly effect the hourly wage.

#proposed solution
(1) On average, unsafe sex decreases the log hourly wage by 0.035
(2) On average, unsafe sex decreases the hourly wage by ± 3.5%

Interpretation 2 utilizes the log-level interpretation of the regression. Technically, the size of the effect is (exp B1 - 1) * 100%, for small values of B1, exp B1-1 = ± B

Statistical significance: the p-value = .198 > .05, so the effect is not statistically significant at the 5% level of significance.


6. A single variable regression most likely suffers from omitted variable bias. 
Explain what omitted variable bias is, and why it might impact your regression estimates.

The omitted variable bias is the bias in the OLS estimator that arises when the regressor, X, is correlated with an omitted variable (non-included variables in the model which are determinants of the dependent variable). For omitted variable bias to occur, two conditions must be fulfilled:
1. X is correlated with the omitted variable
2. The omitted variable is a determinant of the dependent variable Y.
Together, these result in a violation of the first OLS assumption E(u(i) | X(i)) = 0.

This might imparct our regression estimates, because the dependent variable has not been optimally explained and not including these omitted variables might return either false positives in findings or non-statistical findings because not all determinants have been included in the analysis.


7. Add the log of the length of the session, `llength`, as a second variable to your regression.
Report the results.
Did the coefficient on `unsafe` change?

```{r}

reg2 <- lm(unsafe ~ lnw + llength, sex_data)
summary(reg2)

# The p-value of the overall test = <.001 which implies statistical significance
# However, neither the intercept nor the coefficient of lnw are statistically significant.
# Only the llength has a (small positive; 6,5%) statistical signficant effect on unsafe, which means that a longer length of the session increases the likelihood for a session to have included unsafe sex.

#Regr estimate = 0.241956 (p >.05)

```


8. Explain why ignoring `llength` in your regression led to the coefficient on `unsafe` to be different in sign in the single variable regression than in the two variable regression.

Write your answer here

9.  Add a third variable to the regression, whether the client is a regular or not (`reg` in the data).
Report your results and comment on any change in the regression estimate of `unsafe`.

```{r}
reg3 <- lm(unsafe ~ lnw + llength + reg, sex_data)
summary(reg3)

# Regr. estimate of unsafe = 0228257 (p>.05) --> not statistically significant

```


10. When discussing your interim results with a friend who is a bit of a statistical whiz they make the following remark: "I think you're not getting the expected results due to unobserved heterogeneity. Try adding fixed effects for each provider."
What is unobserved heterogeneity? Why might it matter?

Unobserved heterogeneity implies there is a group difference within the sample (unobserved), within groups there is homogeneity, but across groups there is heterogeneity. It matters because researchers can be severely misled if not accounting for these group differences.

11. The data has a unique identifier for each provider in the `id` column.
Use the `feols()` command from the `fixest` package to re-estimate your regression in (9) adding the provider ID fixed effects.
Report your results with 'normal' standard errors (i.e. no clustering).

```{r}

library(fixest)

ols_fe <- feols(unsafe ~ lnw + llength + reg 
                | #Fixed effects go after the |
                    id,
                data = sex_data)

summary(ols_fe)

# Estimates of all IVs are significant at least at the 10% level

coefs_fe <- tidy(ols_fe, se ="standard", conf.int = TRUE)
coefs_fe

# Non-clustered standard errors --> all IVs statistically significant <.001 

```


12. Interpret your new results from (11).
Is the coefficient on `unsafe` now statistically significant?
Is the coefficient large from a 'marketing' viewpoint?

Where exactly can I find the coefficient on unsafe????

Your next concern should be the standard errors - and whether we have 'correctly' adjusted for heteroskedasticity and/or clustering.

13. Produce a plot that visualizes the relationship between the predicted values of `lnw` from your regression on the horizontal axis and the residuals from the regression on the vertical axis.^[
The function `predict(MODEL_NAME)` will create a column of predicted values from a regression stored as `MODEL_NAME`.
The function `residuals(MODEL_NAME)` will create a column of residual values from a regression stored as `MODEL_NAME`.
]
Does there appear to be evidence of heteroskedasticity?


```{r}

pred_val <- predict(ols_fe)
pred_val
res_val <- residuals(ols_fe)
res_val

df <- cbind(pred_val, res_val)
df <- data.frame(df)

ggplot(df, aes(x = pred_val, y = res_val)) +
    geom_point()

# Yes, there appears to be evidence of heteroskedasticity

# Or I could do:

sex_data <- sex_data %>%
    mutate(
        residuals = resid(ols_fe),
        fitted_val = predict(ols_fe)
    )

sex_data %>%
    ggplot(aes(x = fitted_val, 
               y = residuals,
               alpha = 0.35)) +
    geom_point() +
    theme_bw() +
    theme(legend.position = "none")

```


14. Report regression results that use heteroskedasticity robust standard errors. 
You might be able to do this **without** re-estimating the regression model in (11). 
Does the standard error on `unsafe` change by much?
Is this consistent with what you found graphically above?

```{r}
#install.packages("estimatr")
library(estimatr)
library(broom)

ols1a <- lm_robust(unsafe ~ lnw + llength + reg | id,
                   data = sex_data)

tidy(ols1a, conf.int = TRUE)

```


15. Report results that allow the standard errors to be clustered by `id` (i.e. clustered at the provider level).
Again, you might be able to do this **without** re-estimating the regression model in (11). 
Why might you want to cluster the standard errors this way?

```{r}

ols2 <- lm_robust(unsafe ~ lnw + llength + reg | id,
                  clusters = id,
                  data = sex_data)

tidy(ols2, conf.int = TRUE)

```


Marketers are generally interested in whether effects they find are heterogeneous, i.e. whether the reported coefficients vary across different observable characteristics.

16. Estimate a regression model that allows the price effect of unsafe sex to differ for customers who are regulars to those who aren't.
Do this by modifying your regression command from (11).
Report your results and discuss your findings.

```{r}

ols2a <- feols(unsafe ~ lnw + llength + id |
                   reg,
               data = sex_data)

tidy(ols2a, se = "standard", conf.int = TRUE)

```


17. Interpret the results you found in (16).

???

18. Are the effects you documented *causal*, *descriptive* or *predictive*?  Explain your answer.

Descriptive, because ...

Now that you have run a series of regressions, you want to present the results in a way that you could use in a report or a presentation.

19. Take your regression estimates and produce a regression table to summarize four of them in one place. 
You can choose any of the estimates you like to produce the table, but we encourage you to think about how each column adds something to a story you could tell to explain your findings.
The final result should look similar to a regression table you see in academic publications.

```{r}
# Write your answer here
```

20. Take your regression estimates and produce a coefficient plot to summarize four of them in one place. 
You can choose any of the estimates you like to produce the plot, but we encourage you to think about the plot you produce can be used as part of a story you could tell to explain your findings.

```{r}
# Write your answer here
```

## License

This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).

## Suggested Citation

Deer, Lachlan and de With, Hendrik. 2021. Social Media and Web Analytics: Lab 2 - Multiple Regression in the Wild. Tilburg University. url = "https://github.com/tisem-digital-marketing/smwa-lab-02"
